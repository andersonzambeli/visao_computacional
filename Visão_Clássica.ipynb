{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OEEIr8SuQY-o"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vhAMaIOBIee"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import re\n",
        "import random as rd\n",
        "import torch\n",
        "from torchvision import ops\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "from ast import literal_eval\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ord(a, b):\n",
        "  if a > b:\n",
        "    x_ = a\n",
        "    a = b\n",
        "    b = x_\n",
        "    return a , b\n",
        "  else:\n",
        "    return a, b\n",
        "\n",
        "\n",
        "\n",
        "def make_rectangle(xmax_,xmin_,ymax_,ymin_):\n",
        "\n",
        "    x1 = rd.uniform(0,2703)\n",
        "    x2 = rd.uniform(0,2073)\n",
        "    x1, x2 = ord(x1, x2)\n",
        "    # print(\"X1 e x2:  \",x1,x2)\n",
        "    while( (x2 - x1 > xmax_) or (x2 - x1 < xmin_)) :\n",
        "      x2 = rd.uniform(0,2073)\n",
        "      # print(\"Novo x2;  \",x2)\n",
        "      x1, x2 = ord(x1, x2)\n",
        "      # print(\"Novo X1 e X2;  \",x1, x2)\n",
        "\n",
        "\n",
        "    y1 = rd.uniform(0,1519)\n",
        "    y2 = rd.uniform(0,1519)\n",
        "    y1, y2 = ord(y1, y2)\n",
        "    # print(\"Y1 e Y2:  \",x1,x2)\n",
        "    while( (y2 - y1 > ymax_) or (y2 - y1 < ymin_)):\n",
        "      y2 = rd.uniform(0,1519)\n",
        "      # print(\"Novo Y2;  \",y2)\n",
        "      y1, y2 = ord(y1, y2)\n",
        "      # print(\"Novo Y1 e Y2;  \",y1, y2)\n",
        "\n",
        "\n",
        "    # print(\"X :\")\n",
        "    # print(x1, x2)\n",
        "    # print(abs(x2 - x1))\n",
        "    # print(\"Y :\")\n",
        "    # print(y1, y2)\n",
        "    # print(abs(y2 - y1))\n",
        "\n",
        "    return x1,x2,y1,y2\n",
        "\n",
        "\n",
        "# a1 = 205.4000000000001 # max de x2 - x1\n",
        "# b1 = 397.70000000000005 # max de y2 - y1\n",
        "# a2 = 4.7999999999999545\n",
        "# b2 = 5.899999999999864\n",
        "# c1,c2,d1,d2 = make_rectangle(a1,a2,b1,b2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ltXRu4yesrTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# paramentros"
      ],
      "metadata": {
        "id": "OXqWxf2OWXo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# folga na area das anotações\n",
        "space = 1\n",
        "# HOG paramentros\n",
        "cell_size = 8\n",
        "cell_block = 2\n",
        "hog_w_size = 64\n",
        "hog_h_size = 80\n",
        "# area do roi\n",
        "w_param = 1.4\n",
        "h_param = 1.4\n",
        "iou_threshold = 0.5\n",
        "# Hough\n",
        "param = 1.5\n",
        "min_dis = 20\n",
        "val1 = 40\n",
        "val2 = 20"
      ],
      "metadata": {
        "id": "nplwW9h2WUqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Donwload das Imagens"
      ],
      "metadata": {
        "id": "UpsTGIouszBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/andersonzambeli/visao_computacional.git images"
      ],
      "metadata": {
        "id": "3Cnssww_syEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/archive/train_dataset/train_images/00005.jpg')\n",
        "display(img[...,::-1])\n",
        "plt.imshow(img[...,::-1])\n",
        "plt.show()\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "WhYghhrUs10q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pega os as informações dos box das imagens de treino"
      ],
      "metadata": {
        "id": "UgZwS070aK4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/archive/train_dataset/train.json\") as f:\n",
        "    data_dict = json.load(f)\n",
        "\n",
        "# Create a list containing the data rows of the table\n",
        "data = []\n",
        "files_ = sorted(os.listdir(path = \"/content/drive/MyDrive/archive/train_dataset/train_images\"))\n",
        "print(files_)\n",
        "print(len(files_))\n",
        "\n",
        "not_num = 0\n",
        "\n",
        "# Loop through the elements in the annotations list\n",
        "for annotation in data_dict['annotations']:\n",
        "    # Get general bounding box information\n",
        "    filename = annotation['filename']\n",
        "    temp_str = re.sub('train_images\\\\\\\\', '', filename)\n",
        "    if(temp_str not in files_):\n",
        "       continue\n",
        "\n",
        "    # if annotation[\"ignore\"]:\n",
        "    #   ignore = annotation[\"ignore\"]\n",
        "    #   if ignore == 1:\n",
        "    #     continue\n",
        "    xmin = annotation['bndbox']['xmin']\n",
        "    ymin = annotation['bndbox']['ymin']\n",
        "    xmax = annotation['bndbox']['xmax']\n",
        "    ymax = annotation['bndbox']['ymax']\n",
        "\n",
        "    if annotation['inbox']:\n",
        "\n",
        "        for inbox in annotation['inbox']:\n",
        "            color = inbox['color']\n",
        "            if color == \"yellow\":\n",
        "              continue\n",
        "            shape = inbox['shape']\n",
        "            # if (shape == str(-1) or shape == str(0)):\n",
        "            if (True):\n",
        "              not_num += 1\n",
        "\n",
        "              data.append({\n",
        "                      'filename': filename,\n",
        "                      'xmin': xmin,\n",
        "                      'ymin': ymin,\n",
        "                      'xmax': xmax,\n",
        "                      'ymax': ymax,\n",
        "                      'color': color,\n",
        "                  })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a DataFrame from a list of data and save it to a CSV file\n",
        "print(data)\n",
        "df = pd.DataFrame(data)\n",
        "df['filename'] = df['filename'].str.replace('train_images\\\\\\\\', '', regex=True)\n",
        "df.to_csv('traffic_lights.csv', index=False)\n",
        "print(df['color'].unique())\n",
        "df.head()\n",
        "print(not_num)"
      ],
      "metadata": {
        "id": "QT3gulJoaZ_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vizualização de uma imagem com os bboxes"
      ],
      "metadata": {
        "id": "uBpnR6dIokFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_name = \"00051.jpg\"\n",
        "\n",
        "df_img_show = df.loc[df['filename'] == img_name]\n",
        "df_img_show = df_img_show.reset_index()\n",
        "print(df_img_show)\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/archive/train_dataset/train_images/' + img_name)\n",
        "\n",
        "for i in range(len(df_img_show.index)):\n",
        "  x1b = df_img_show.at[i,\"xmin\"]\n",
        "  x2b = df_img_show.at[i,\"xmax\"]\n",
        "  y1b = df_img_show.at[i,\"ymin\"]\n",
        "  y2b = df_img_show.at[i,\"ymax\"]\n",
        "  img = cv2.rectangle(img, (int(x1b), int(y1b)), (int(x2b), int(y2b)), (0, 0, 255), 2)\n",
        "  cv2.putText(img, df_img_show.at[i,\"color\"] , (int(x1b), int(y1b-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "\n",
        "\n",
        "cv2_imshow(img)\n"
      ],
      "metadata": {
        "id": "CZ67xOV3op4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividindo o dataset em parte de treino e parte de teste"
      ],
      "metadata": {
        "id": "uxXtmXi1ok2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(files_))\n",
        "\n",
        "rd.shuffle(files_)\n",
        "\n",
        "files_train = files_[0:600]\n",
        "print(len(files_train))\n",
        "files_test = files_[601:701]\n",
        "print(len(files_test))\n",
        "\n",
        "df_train = df[0:600]\n",
        "print(df_train.shape)"
      ],
      "metadata": {
        "id": "V-pYa2isott8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinando um algoritmo usando HOG com as bound boxes das imagens de treinamento"
      ],
      "metadata": {
        "id": "Ox-lOScNMGCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contagem do numero de boxes de cada classe(green ou red)"
      ],
      "metadata": {
        "id": "CW0bWj_oNb4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reds=0\n",
        "greens=0\n",
        "for i in range(len(df_train.index)):\n",
        "  if df.at[i,\"color\"] == \"red\":\n",
        "    reds += 1\n",
        "  if df.at[i,\"color\"] == \"green\":\n",
        "    greens += 1\n",
        "print(\"Reds: \", reds)\n",
        "print(\"Greens: \", greens)\n",
        "print(\"Total: \", str(reds+greens))\n",
        "\n"
      ],
      "metadata": {
        "id": "4HGnPkqDNWe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Achando o maior valor de distancia em x e y para cada bound box e a mesma coisa para y"
      ],
      "metadata": {
        "id": "dtpXjLS_WcAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#usar proporção TODO\n",
        "\n",
        "xmax = 0\n",
        "ymax = 0\n",
        "xmin = 3000\n",
        "ymin = 3000\n",
        "for i in range(len(df_train.index)):\n",
        "  x_dist = df.at[i,\"xmax\"] - df.at[i,\"xmin\"]\n",
        "  y_dist = df.at[i,\"ymax\"] - df.at[i,\"ymin\"]\n",
        "  if x_dist > xmax:\n",
        "    xmax = x_dist\n",
        "  if x_dist < xmin:\n",
        "    xmin = x_dist\n",
        "  if y_dist > ymax:\n",
        "    ymax = y_dist\n",
        "  if y_dist < ymin:\n",
        "    ymin = y_dist\n",
        "\n",
        "rz1 = ymax / xmax\n",
        "rz2 = ymin / xmin\n",
        "rz_opt = 1.5\n",
        "\n",
        "print(rz1)\n",
        "print(rz2)\n",
        "print(xmax, ymax, xmin, ymin)"
      ],
      "metadata": {
        "id": "PLS65rCSWbez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pra cada imagem de treino, vamos gerar um número maximo de bound box em algum lugar fora das bound boxes de semáforo que seja igual ao numero de bound boxes de semáforo. Assim o algoritmo consgue saber o que não é semáfaro"
      ],
      "metadata": {
        "id": "iQBvkzntMR0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "k = len(df_train.index)\n",
        "max = 150\n",
        "count = 0\n",
        "for i in range(k):\n",
        "  # print('')\n",
        "  # print(\"Para i : \" + str(i))\n",
        "  if i == k:\n",
        "    break\n",
        "  df_file = df_train.loc[df_train['filename'] == df_train.at[i,\"filename\"]]\n",
        "  filename_ = df_train.at[i,\"filename\"]\n",
        "  df_file = df_file.reset_index()\n",
        "  # print(\"Nome da imagem: \" + filename_)\n",
        "  if count > max:\n",
        "        break\n",
        "\n",
        "\n",
        "  x1,x2,y1,y2 = make_rectangle(xmax,xmin,ymax,ymin)\n",
        "  # print(\"Rec criado\",x1,x2,y1,y2)\n",
        "  # img_test=img.copy()\n",
        "  if i < k:\n",
        "    for j in range(len(df_file.index)):\n",
        "      if j == 0:\n",
        "        img_test = cv2.imread('/content/drive/MyDrive/archive/train_dataset/train_images/' + df_file.at[j,\"filename\"])\n",
        "      x1b = df_file.at[j,\"xmin\"]\n",
        "      x2b = df_file.at[j,\"xmax\"]\n",
        "      y1b = df_file.at[j,\"ymin\"]\n",
        "      y2b = df_file.at[j,\"ymax\"]\n",
        "      img_test = cv2.rectangle(img_test, (int(x1b), int(y1b)), (int(x2b), int(y2b)), (0, 0, 255), 2)\n",
        "      bbox_rec = torch.tensor([[x1,y1,x2,y2]], dtype=torch.float)\n",
        "      bbox_file = torch.tensor([[x1b,y1b,x2b,y2b]], dtype=torch.float)\n",
        "      iou = ops.box_iou(bbox_file, bbox_rec)\n",
        "      # print(\"Iou \", str(j),\" :\",iou.numpy()[0][0], )\n",
        "\n",
        "      # 1.9362220058422583 1\n",
        "      # 1.2291666666666499 2\n",
        "\n",
        "      while((iou.numpy()[0][0] != 0) and (y2/x2 > rz1 or y2/x2 < rz2 )):\n",
        "\n",
        "        x1,x2,y1,y2 = make_rectangle(xmax,xmin,ymax,ymin)\n",
        "        # print(\"Novo Rec criado: \",x1,x2,y1,y2)\n",
        "        bbox_rec = torch.tensor([[x1,y1,x2,y2]], dtype=torch.float)\n",
        "        iou = ops.box_iou(bbox_file, bbox_rec)\n",
        "        # print(\"Recalculando iou: \" + str(j) )\n",
        "        # (print(\"Novo Iou \", str(j),\" :\" ,iou.numpy()[0][0] ))\n",
        "        # print(i)\n",
        "\n",
        "\n",
        "    df2 = {'filename': filename_, 'xmin': x1, 'ymin': y1,'xmax': x2, 'ymax': y2,'color': \"None\"}\n",
        "    count += 1\n",
        "    df_train = df_train._append(df2, ignore_index = True)\n",
        "    img_test = cv2.rectangle(img_test, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
        "    # cv2_imshow(img_test)\n",
        "    df_file = df_train.loc[df_train['filename'] == df_train.at[i,\"filename\"]]\n",
        "    # print(df_train.tail())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q4WB6zTJsgVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processando as imagens da bbox"
      ],
      "metadata": {
        "id": "bYVN3vVXTcwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import feature\n",
        "\n",
        "print(df_train.shape)\n",
        "\n",
        "img_ind = 380\n",
        "print(files_train[img_ind])\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/archive/train_dataset/train_images/' + files_train[img_ind] )\n",
        "\n",
        "\n",
        "\n",
        "image = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "cv2_imshow(image)\n",
        "\n"
      ],
      "metadata": {
        "id": "ozHihNyj6aDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retinex"
      ],
      "metadata": {
        "id": "OEEIr8SuQY-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicação do retinex"
      ],
      "metadata": {
        "id": "tDhoDpJHzG0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def singleScaleRetinex(img,variance):\n",
        "    retinex = np.log10(img) - np.log10(cv2.GaussianBlur(img, (0, 0), variance))\n",
        "    return retinex\n",
        "\n",
        "def multiScaleRetinex(img, variance_list):\n",
        "    retinex = np.zeros_like(img)\n",
        "    for variance in variance_list:\n",
        "        retinex += singleScaleRetinex(img, variance)\n",
        "    retinex = retinex / len(variance_list)\n",
        "    return retinex\n",
        "\n",
        "\n",
        "\n",
        "def MSR(img, variance_list):\n",
        "    img = np.float64(img) + 1.0\n",
        "    img_retinex = multiScaleRetinex(img, variance_list)\n",
        "\n",
        "    for i in range(img_retinex.shape[2]):\n",
        "        unique, count = np.unique(np.int32(img_retinex[:, :, i] * 100), return_counts=True)\n",
        "        for u, c in zip(unique, count):\n",
        "            if u == 0:\n",
        "                zero_count = c\n",
        "                break\n",
        "        low_val = unique[0] / 100.0\n",
        "        high_val = unique[-1] / 100.0\n",
        "        for u, c in zip(unique, count):\n",
        "            if u < 0 and c < zero_count * 0.1:\n",
        "                low_val = u / 100.0\n",
        "            if u > 0 and c < zero_count * 0.1:\n",
        "                high_val = u / 100.0\n",
        "                break\n",
        "        img_retinex[:, :, i] = np.maximum(np.minimum(img_retinex[:, :, i], high_val), low_val)\n",
        "\n",
        "        img_retinex[:, :, i] = (img_retinex[:, :, i] - np.min(img_retinex[:, :, i])) / \\\n",
        "                               (np.max(img_retinex[:, :, i]) - np.min(img_retinex[:, :, i])) \\\n",
        "                               * 255\n",
        "    img_retinex = np.uint8(img_retinex)\n",
        "    return img_retinex\n",
        "\n",
        "\n",
        "\n",
        "def SSR(img, variance):\n",
        "    img = np.float64(img) + 1.0\n",
        "    img_retinex = singleScaleRetinex(img, variance)\n",
        "    for i in range(img_retinex.shape[2]):\n",
        "        unique, count = np.unique(np.int32(img_retinex[:, :, i] * 100), return_counts=True)\n",
        "        for u, c in zip(unique, count):\n",
        "            if u == 0:\n",
        "                zero_count = c\n",
        "                break\n",
        "        low_val = unique[0] / 100.0\n",
        "        high_val = unique[-1] / 100.0\n",
        "        for u, c in zip(unique, count):\n",
        "            if u < 0 and c < zero_count * 0.1:\n",
        "                low_val = u / 100.0\n",
        "            if u > 0 and c < zero_count * 0.1:\n",
        "                high_val = u / 100.0\n",
        "                break\n",
        "        img_retinex[:, :, i] = np.maximum(np.minimum(img_retinex[:, :, i], high_val), low_val)\n",
        "\n",
        "        img_retinex[:, :, i] = (img_retinex[:, :, i] - np.min(img_retinex[:, :, i])) / \\\n",
        "                               (np.max(img_retinex[:, :, i]) - np.min(img_retinex[:, :, i])) \\\n",
        "                               * 255\n",
        "    img_retinex = np.uint8(img_retinex)\n",
        "    return img_retinex\n",
        "\n",
        "\n",
        "variance_list=[15, 80, 30]\n",
        "variance=300"
      ],
      "metadata": {
        "id": "jyYJMZiazF76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# img_ssr=SSR(img, variance)\n",
        "\n",
        "\n",
        "# plt.imshow(img_ssr[...,::-1])\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "MGH0dOKU0qNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentação por cor"
      ],
      "metadata": {
        "id": "Vvic82GtvVk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conversão da imagem para HSV**"
      ],
      "metadata": {
        "id": "r7VI2f9dqfXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sem retinex"
      ],
      "metadata": {
        "id": "0celKkZqRfTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformar para colormap para hsv"
      ],
      "metadata": {
        "id": "NOP-kDQcah24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_hsv=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
        "\n",
        "\n",
        "\n",
        "# display(img_hsv[...,::1])\n",
        "plt.imshow(img_hsv[...,::1])\n",
        "plt.show()\n",
        "# display(img_hsv[...,::-1])\n",
        "plt.imshow(image[...,::-1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mb1DwLvO3P0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicação de threshold de cores verde e vermelho e obtenção de aŕeas de interesse"
      ],
      "metadata": {
        "id": "3Nbk6qE6rENZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos o valores de threshold e criamos mascaras para achar regiões onde é verde e vermelho"
      ],
      "metadata": {
        "id": "klRgErtMwWAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o vermelho"
      ],
      "metadata": {
        "id": "solJe8r1hKBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lower_red1 = np.array([0,100,100])\n",
        "upper_red1 = np.array([8,255,255])\n",
        "lower_red2 = np.array([160, 150, 90])\n",
        "upper_red2 = np.array([180, 255, 255])\n",
        "\n",
        "mask1 = cv2.inRange(img_hsv, lower_red1, upper_red1)\n",
        "mask2 = cv2.inRange(img_hsv, lower_red2, upper_red2)\n",
        "\n",
        "maskr = cv2.add(mask1, mask2)\n",
        "\n",
        "# Fechamento\n",
        "element = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10,10))\n",
        "closed_r  = cv2.morphologyEx(maskr, cv2.MORPH_CLOSE, element)\n",
        "thresholded = closed_r\n",
        "# (thresh1, thresholded) = cv2.threshold(closed_r, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "\n",
        "\n",
        "# Calculos dos circulos de hogh\n",
        "\n",
        "\n",
        "circles_red = cv2.HoughCircles(thresholded, cv2.HOUGH_GRADIENT, param, min_dis, param1=val1, param2= val2, minRadius=1, maxRadius=100)\n",
        "NoneType = type(None)\n",
        "if not isinstance(circles_red, NoneType):\n",
        "  circles = np.uint16(np.around(circles_red))\n",
        "  for i in circles[0,:]:\n",
        "    # draw the outer circle\n",
        "    cv2.circle(closed_r,(i[0],i[1]),i[2],(255,0,0),2)\n",
        "    # draw the center of the circle\n",
        "    cv2.circle(closed_r,(i[0],i[1]),2,(0,0,255),3)\n",
        "\n",
        "cv2_imshow(closed_r)\n",
        "\n",
        "plt.imshow(closed_r[...,::1])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "YNM-dhEVhEuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o verde"
      ],
      "metadata": {
        "id": "ZCny0u0LZMw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lower_green = np.array([40, 120, 120])\n",
        "upper_green = np.array([90, 255, 255])\n",
        "\n",
        "maskg = cv2.inRange(img_hsv, lower_green, upper_green)\n",
        "\n",
        "\n",
        "\n",
        "# Fechamento\n",
        "closed_g  = cv2.morphologyEx(maskg, cv2.MORPH_CLOSE, element)\n",
        "thresholded = closed_g\n",
        "# (thresh1, thresholded) = cv2.threshold(closed_g, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "#calculo do ciculo de hough\n",
        "circles_green = cv2.HoughCircles(thresholded, cv2.HOUGH_GRADIENT, param, min_dis, param1=val1, param2=val2, minRadius=2, maxRadius=100)\n",
        "NoneType = type(None)\n",
        "if not isinstance(circles_green, NoneType):\n",
        "  circles = np.uint16(np.around(circles_green))\n",
        "  for i in circles[0,:]:\n",
        "    # draw the outer circle\n",
        "    cv2.circle(closed_g,(i[0],i[1]),i[2],(255,0,0),2)\n",
        "    # draw the center of the circle\n",
        "    cv2.circle(closed_g,(i[0],i[1]),2,(0,0,255),3)\n",
        "\n",
        "cv2_imshow(closed_g)\n",
        "\n",
        "plt.imshow(closed_g[...,::-1])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "wwR2NTyZZdvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "gradient_image = filters.sobel(gray_image)\n"
      ],
      "metadata": {
        "id": "khA-tzc27VDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframe de Areas de interesse(ROI) da imagem"
      ],
      "metadata": {
        "id": "9sMAiyCnOVzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_anot = image.copy()\n",
        "cv2_imshow(image_anot)\n",
        "\n",
        "w_param = 1.3\n",
        "h_param = 1.3\n",
        "iou_threshold = 0.5\n",
        "\n",
        "roi_df = pd.DataFrame()\n",
        "\n",
        "if not isinstance(circles_red, NoneType):\n",
        "  circles = np.uint16(np.around(circles_red))\n",
        "  for r in circles[0,:]:\n",
        "\n",
        "    xmin_r = r[0] - w_param*r[2]\n",
        "    xmax_r = r[0] + w_param*r[2]\n",
        "    ymin_r = r[1] - h_param*r[2]\n",
        "    ymax_r = r[1] + 5 * h_param * r[2]\n",
        "\n",
        "\n",
        "    roi_df = pd.concat([roi_df, pd.DataFrame([{\"filename\": img_name, \"xmin\": xmin_r , \"ymin\": ymin_r, \"xmax\": xmax_r,\"ymax\": ymax_r,\"color\": \"None\"}])], ignore_index=True)\n",
        "    cv2.rectangle(image_anot, (int(xmin_r), int(ymin_r)), (int(xmax_r), int(ymax_r)), (0, 0, 255), 2)\n",
        "\n",
        "    cv2.circle(image_anot,(r[0],r[1]),r[2],(255,0,0),2)\n",
        "    cv2.circle(image_anot,(r[0],r[1]),r[2],(255,0,0),2)\n",
        "    cv2.putText(image_anot, \"red\", (int(r[0]), int(r[1] - r[2] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "\n",
        "    print(r)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not isinstance(circles_green, NoneType):\n",
        "  circles = np.uint16(np.around(circles_green))\n",
        "  for r in circles[0,:]:\n",
        "\n",
        "    xmin_r = r[0] - w_param*r[2]\n",
        "    xmax_r = r[0] + w_param*r[2]\n",
        "    ymin_r = r[1] - 5 * h_param * r[2]\n",
        "    ymax_r = r[1] + h_param * r[2]\n",
        "\n",
        "    roi_df = pd.concat([roi_df, pd.DataFrame([{\"filename\": img_name, \"xmin\": xmin_r , \"ymin\": ymin_r, \"xmax\": xmax_r,\"ymax\": ymax_r,\"color\": \"None\"}])], ignore_index=True)\n",
        "\n",
        "    cv2.rectangle(image_anot, (int(xmin_r), int(ymin_r)), (int(xmax_r), int(ymax_r)), (0, 0, 255), 2)\n",
        "\n",
        "    cv2.circle(image_anot,(r[0],r[1]),r[2],(255,0,0),2)\n",
        "    cv2.putText(image_anot, \"green\", (int(r[0]), int(r[1] - r[2] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "    print(r)\n",
        "\n",
        "print(roi_df)\n",
        "\n",
        "df_imag_anot = df_train.loc[df_train['filename'] == img_name]\n",
        "df_imag_anot = df_imag_anot.reset_index()\n",
        "print(df_imag_anot)\n",
        "\n",
        "for i in range(len(df_imag_anot.index)):\n",
        "  xmin_real = df_imag_anot.at[i,\"xmin\"]\n",
        "  xmax_real = df_imag_anot.at[i,\"xmax\"]\n",
        "  ymin_real = df_imag_anot.at[i,\"ymin\"]\n",
        "  ymax_real = df_imag_anot.at[i,\"ymax\"]\n",
        "  bbox_anot = torch.tensor([[xmin_real,ymin_real,xmax_real,ymax_real]], dtype=torch.float)\n",
        "\n",
        "\n",
        "  for j in range(len(roi_df.index)):\n",
        "    xmin_anot = roi_df.at[j,\"xmin\"]\n",
        "    xmax_anot = roi_df.at[j,\"xmax\"]\n",
        "    ymin_anot = roi_df.at[j,\"ymin\"]\n",
        "    ymax_anot = roi_df.at[j,\"ymax\"]\n",
        "\n",
        "    bbox_roi = torch.tensor([[xmin_anot,ymin_anot,xmax_anot,ymax_anot]], dtype=torch.float)\n",
        "    iou1 = ops.box_iou(bbox_anot, bbox_roi)\n",
        "    iou2 = ops.box_iou(bbox_roi,bbox_anot)\n",
        "\n",
        "    if ((iou1 > iou_threshold) or (iou2> iou_threshold)):\n",
        "      roi_df.at[j,\"color\"] = df_imag_anot.at[i,\"color\"]\n",
        "    print(\"Iou i\", str(i), \" j \", str(j),\" :\",iou.numpy()[0][0], )\n",
        "\n",
        "\n",
        "print(roi_df)\n",
        "\n",
        "cv2_imshow(image_anot)\n",
        "\n",
        "# Gerando bbox para cada círculo:\n"
      ],
      "metadata": {
        "id": "yl4XfXd1OVZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HOG e treino do classifcador"
      ],
      "metadata": {
        "id": "1czq0s1XPUdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import feature\n",
        "from skimage import exposure, filters\n",
        "\n",
        "\n",
        "\n",
        "data_train = []\n",
        "labels_train = []\n",
        "\n",
        "for i in range(len(df_train.index)):\n",
        "  img_name = df_train.at[i,\"filename\"]\n",
        "  # print(img_name)\n",
        "\n",
        "\n",
        "\n",
        "  #   break\n",
        "  img = cv2.imread('/content/drive/MyDrive/archive/train_dataset/train_images/' + img_name, )\n",
        "  image = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "  x1 = df_train.at[i,\"xmin\"]\n",
        "  x2 = df_train.at[i,\"xmax\"]\n",
        "  y1 = df_train.at[i,\"ymin\"]\n",
        "  y2 = df_train.at[i,\"ymax\"]\n",
        "  x1 = x1 - space*x1\n",
        "  x2 = x2 + space*x1\n",
        "  y1 = y1 - space*y1\n",
        "  y2 = y2 + space*y1\n",
        "\n",
        "  # print(\"Retangulo para cortar\",x1,x2,y1,y2)\n",
        "\n",
        "  cropped_image = img[int(y1):int(y2), int(x1):int(x2)]\n",
        "  cropped_resized = cv2.resize(cropped_image, (hog_w_size,hog_h_size))\n",
        "\n",
        "  gray_image = cv2.cvtColor(cropped_resized, cv2.COLOR_RGB2GRAY)\n",
        "  # gradient_image = filters.sobel(gray_image)\n",
        "\n",
        "\n",
        "  # cv2_imshow(cropped_image)\n",
        "  # cv2_imshow(cropped_resized)\n",
        "  # plt.imshow(gray_image, cmap='gray')\n",
        "  # plt.show()\n",
        "  features, hog_image = feature.hog(gray_image, orientations=9,\n",
        "                               pixels_per_cell=(cell_size, cell_size), cells_per_block=(cell_block, cell_block),\n",
        "                               visualize=True,\n",
        "                               transform_sqrt=True, block_norm=\"L2-Hys\")\n",
        "  # plt.imshow(hog_image, cmap='gray')\n",
        "  # plt.show()\n",
        "  if (i == 1 or i == 0):\n",
        "    print(img_name)\n",
        "    cv2_imshow(cropped_image)\n",
        "    cv2_imshow(cropped_resized)\n",
        "    plt.imshow(hog_image, cmap='gray')\n",
        "    plt.show()\n",
        "  label = df_train.at[i,\"color\"]\n",
        "  data_train.append(features)\n",
        "  labels_train.append(label)\n",
        "  # print(label)\n",
        "\n"
      ],
      "metadata": {
        "id": "_DZHXUwWPXJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinando o classificador"
      ],
      "metadata": {
        "id": "4PRtFOtGYSAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "x_train = (np.array(data_train), np.array(labels_train))\n",
        "print(len(labels_train))\n",
        "print(len(data_train))\n",
        "\n",
        "\n",
        "model = RandomForestClassifier(criterion='log_loss', max_depth=10)\n",
        "# model = svm.SVC(decision_function_shape='ovo', probability=True)\n",
        "# model =XGBClassifier()\n",
        "X_train = np.array(data_train)\n",
        "print(X_train.shape)\n",
        "y_train = np.array(labels_train)\n",
        "print(y_train.shape)\n",
        "\n",
        "# # codifique os rótulos\n",
        "le = LabelEncoder()\n",
        "# codifique os rótulos de treino\n",
        "y_train = le.fit_transform(y_train)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "\n",
        "cm=confusion_matrix(y_train,y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2q5fBSu2aaig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pegando o dataframe de anotações dos teste"
      ],
      "metadata": {
        "id": "l8sDlEtzlIxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(files_test)\n",
        "print(len(files_test))\n",
        "\n",
        "not_num = 0\n",
        "data = []\n",
        "# Loop through the elements in the annotations list\n",
        "for annotation in data_dict['annotations']:\n",
        "    # Get general bounding box information\n",
        "    filename = annotation['filename']\n",
        "    temp_str = re.sub('train_images\\\\\\\\', '', filename)\n",
        "    # print(temp_str)\n",
        "\n",
        "    # Pega somente as anotações das fotos da pasta atual\n",
        "    if(temp_str not in files_):\n",
        "       continue\n",
        "\n",
        "    # if annotation[\"ignore\"]:\n",
        "    #   ignore = annotation[\"ignore\"]\n",
        "    #   if ignore == 1:\n",
        "    #     continue\n",
        "    xmin = annotation['bndbox']['xmin']\n",
        "    ymin = annotation['bndbox']['ymin']\n",
        "    xmax = annotation['bndbox']['xmax']\n",
        "    ymax = annotation['bndbox']['ymax']\n",
        "\n",
        "    if annotation['inbox']:\n",
        "\n",
        "        for inbox in annotation['inbox']:\n",
        "            color = inbox['color']\n",
        "            if color == \"yellow\":\n",
        "              continue\n",
        "            shape = inbox['shape']\n",
        "            # if (shape == str(-1) or shape == str(0)):\n",
        "            if (True):\n",
        "              not_num += 1\n",
        "\n",
        "              data.append({\n",
        "                      'filename': filename,\n",
        "                      'xmin': xmin,\n",
        "                      'ymin': ymin,\n",
        "                      'xmax': xmax,\n",
        "                      'ymax': ymax,\n",
        "                      'color': color,\n",
        "                  })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a DataFrame from a list of data and save it to a CSV file\n",
        "# print(data)\n",
        "df_test = pd.DataFrame(data)\n",
        "df_test['filename'] = df_test['filename'].str.replace('train_images\\\\\\\\', '', regex=True)\n",
        "df_test.to_csv('traffic_lights_test.csv', index=False)\n",
        "print(df_test)\n",
        "# print(df_test['color'].unique())\n",
        "# print(df_test.head())\n",
        "# print(not_num)\n",
        "\n",
        "# img_name = \"00029.jpg\"\n",
        "\n",
        "# df_img_show = df_test.loc[df_test['filename'] == img_name]\n",
        "# df_img_show = df_img_show.reset_index()\n",
        "# # print(df_img_show)\n",
        "\n",
        "# img = cv2.imread('/content/images/test_images/' + img_name)\n",
        "\n",
        "# for i in range(len(df_img_show.index)):\n",
        "#   x1t = df_img_show.at[i,\"xmin\"]\n",
        "#   x2t = df_img_show.at[i,\"xmax\"]\n",
        "#   y1t = df_img_show.at[i,\"ymin\"]\n",
        "#   y2t = df_img_show.at[i,\"ymax\"]\n",
        "#   color = df_img_show.at[i,\"color\"]\n",
        "#   # img = cv2.rectangle(img, (int(x1t), int(y1t)), (int(x2t), int(y2t)), (0, 0, 255), 2)\n",
        "#   # cv2.putText(img, str(i), (int(x1t), int(y1t-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "\n",
        "# cropped_image = img[int(y1t):int(y2t), int(x1t):int(x2t)]\n",
        "# cropped_resized = cv2.resize(cropped_image, (32,64))\n",
        "\n",
        "# cv2_imshow(cropped_image)\n",
        "# cv2_imshow(cropped_resized)\n",
        "# features, hog_image = feature.hog(cropped_resized, orientations=9,\n",
        "#                               pixels_per_cell=(cell_size, cell_size), cells_per_block=(2, 2),\n",
        "#                               visualize=True,\n",
        "#                               transform_sqrt=True, block_norm=\"L2-Hys\", multichannel=True)\n",
        "# # plt.imshow(hog_image, cmap='gray')\n",
        "# # plt.show()\n",
        "\n",
        "# data=[]\n",
        "# labels = []\n",
        "# data.append(features)\n",
        "# labels.append(color)\n",
        "\n",
        "# x_test = np.array(data), np.array(labels)\n",
        "# print(len(labels))\n",
        "# print(len(data))\n",
        "# pred = model.predict(x_test[0])\n",
        "# print(\"Resultado: \", pred)\n",
        "\n",
        "# # cv2_imshow(img)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lyx4TiRGlMxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gerando as Roi para todas as imagens"
      ],
      "metadata": {
        "id": "CvoBuWFx6ASY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf `find -type d -name .ipynb_checkpoints`"
      ],
      "metadata": {
        "id": "wAtbofWmghcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_roi=pd.DataFrame()\n",
        "\n",
        "Iou_count = 0\n",
        "\n",
        "for f in files_test:\n",
        "  img_original = cv2.imread('/content/drive/MyDrive/archive/train_dataset/train_images/' + f)\n",
        "  name_img = f\n",
        "  # name_img = \"02853.jpg\"\n",
        "  # img_original = cv2.imread('/content/drive/MyDrive/archive/train_dataset//train_images/' + name_img)\n",
        "\n",
        "  # Passando filtro gaussiano:\n",
        "\n",
        "  print(f)\n",
        "  img_gauss_blur = cv2.GaussianBlur(img_original, (3, 3), 0)\n",
        "  img_hsv=cv2.cvtColor(img_gauss_blur,cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  ########### Achando as rois vermelhas  ###########\n",
        "\n",
        "  # Máscaras usadas\n",
        "  lower_red1 = np.array([0,100,100])\n",
        "  upper_red1 = np.array([8,255,255])\n",
        "  lower_red2 = np.array([160, 150, 90])\n",
        "  upper_red2 = np.array([180, 255, 255])\n",
        "\n",
        "  #  Passandos as máscaras\n",
        "  mask1 = cv2.inRange(img_hsv, lower_red1, upper_red1)\n",
        "  mask2 = cv2.inRange(img_hsv, lower_red2, upper_red2)\n",
        "\n",
        "  maskr = cv2.add(mask1, mask2)\n",
        "\n",
        "  # Fechamento das áreas geradas\n",
        "  element = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20,20))\n",
        "  closed_r  = cv2.morphologyEx(maskr, cv2.MORPH_CLOSE, element)\n",
        "\n",
        "  thresholded = closed_r\n",
        "  # (thresh1, thresholded) = cv2.threshold(closed_r, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "  # Calculos dos circulos de hogh\n",
        "  circles_red = cv2.HoughCircles(thresholded, cv2.HOUGH_GRADIENT, param, min_dis, param1=40, param2=20, minRadius=2, maxRadius=100)\n",
        "  NoneType = type(None)\n",
        "  if not isinstance(circles_red, NoneType):\n",
        "    circles = np.uint16(np.around(circles_red))\n",
        "    for i in circles[0,:]:\n",
        "      # contorno\n",
        "      cv2.circle(closed_r,(i[0],i[1]),i[2],(255,0,0),2)\n",
        "      # centro\n",
        "      cv2.circle(closed_r,(i[0],i[1]),2,(0,0,255),3)\n",
        "\n",
        "\n",
        "\n",
        "  ############ Gerando rois verdes ###########\n",
        "\n",
        "  lower_green = np.array([40, 120, 120])\n",
        "  upper_green = np.array([90, 255, 255])\n",
        "\n",
        "  maskg = cv2.inRange(img_hsv, lower_green, upper_green)\n",
        "\n",
        "\n",
        "\n",
        "# Fechamento\n",
        "  closed_g  = cv2.morphologyEx(maskg, cv2.MORPH_CLOSE, element)\n",
        "\n",
        "# OSTU\n",
        "  thresholded = closed_g\n",
        "  # (thresh1, thresholded) = cv2.threshold(closed_g, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "#calculo do ciculo de hough\n",
        "  circles_green = cv2.HoughCircles(thresholded, cv2.HOUGH_GRADIENT, param, min_dis, param1=val1, param2=val2, minRadius=1, maxRadius=100)\n",
        "  NoneType = type(None)\n",
        "  if not isinstance(circles_green, NoneType):\n",
        "    circles = np.uint16(np.around(circles_green))\n",
        "    for i in circles[0,:]:\n",
        "      # draw the outer circle\n",
        "      cv2.circle(closed_g,(i[0],i[1]),i[2],(255,0,0),2)\n",
        "      # draw the center of the circle\n",
        "      cv2.circle(closed_g,(i[0],i[1]),2,(0,0,255),3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #################### Criação das rois #################\n",
        "\n",
        "\n",
        "\n",
        "  data_roi_loc = pd.DataFrame()\n",
        "\n",
        "  image_anot = img_original.copy()\n",
        "  # Para cor vermelha\n",
        "  if not isinstance(circles_red, NoneType):\n",
        "    circles = np.uint16(np.around(circles_red))\n",
        "    for r in circles[0,:]:\n",
        "\n",
        "      xmin_r = r[0] - w_param*r[2]\n",
        "      if(xmin_r <= 0):\n",
        "        xmin_r = 0\n",
        "      xmax_r = r[0] + w_param*r[2]\n",
        "      if(xmax_r >= 2703):\n",
        "        xmax_r = 2703\n",
        "      ymin_r = r[1] - h_param*r[2]\n",
        "      if(ymin_r <= 0):\n",
        "        ymin_r = 0\n",
        "      ymax_r = r[1] + 5 * h_param * r[2]\n",
        "      if(ymax_r >= 1519):\n",
        "        yman_r = 1519\n",
        "      if f == \"00232.jpg\":\n",
        "        print(xmax_r,ymax_r,xmin_r,ymin_r)\n",
        "\n",
        "\n",
        "      data_roi_loc = pd.concat([data_roi_loc, pd.DataFrame([{\"filename\": name_img, \"xmin\": xmin_r , \"ymin\": ymin_r, \"xmax\": xmax_r,\"ymax\": ymax_r,\"color\": \"None\"}])], ignore_index=True)\n",
        "      cv2.rectangle(image_anot, (int(xmin_r), int(ymin_r)), (int(xmax_r), int(ymax_r)), (0, 0, 255), 2)\n",
        "\n",
        "      cv2.circle(image_anot,(r[0],r[1]),r[2],(255,0,0),2)\n",
        "      cv2.circle(image_anot,(r[0],r[1]),r[2],(255,0,0),2)\n",
        "      cv2.putText(image_anot, \"red\", (int(r[0]), int(r[1] - r[2] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "\n",
        "      if f == \"00232.jpg\":\n",
        "        print(r)\n",
        "\n",
        "\n",
        "\n",
        "  # Para cor verde\n",
        "  if not isinstance(circles_green, NoneType):\n",
        "    circles = np.uint16(np.around(circles_green))\n",
        "    for r in circles[0,:]:\n",
        "\n",
        "      xmin_r = r[0] - w_param*r[2]\n",
        "      if(xmin_r <= 0):\n",
        "        xmin_r = 0\n",
        "      xmax_r = r[0] + w_param*r[2]\n",
        "      if(xmax_r >= 2703):\n",
        "        xmax_r = 2703\n",
        "      ymin_r = r[1] - 5 * h_param * r[2]\n",
        "      if(ymin_r <= 0):\n",
        "        ymin_r = 0\n",
        "      ymax_r = r[1] + h_param * r[2]\n",
        "      if(ymax_r >= 1519):\n",
        "        ymax_r = 1519\n",
        "      if f == \"00232.jpg\":\n",
        "        print(xmax_r,ymax_r,xmin_r,ymin_r)\n",
        "\n",
        "      data_roi_loc = pd.concat([data_roi_loc, pd.DataFrame([{\"filename\": name_img, \"xmin\": xmin_r , \"ymin\": ymin_r, \"xmax\": xmax_r,\"ymax\": ymax_r,\"color\": \"None\"}])], ignore_index=True)\n",
        "\n",
        "      cv2.rectangle(image_anot, (int(xmin_r), int(ymin_r)), (int(xmax_r), int(ymax_r)), (0, 0, 255), 2)\n",
        "\n",
        "      cv2.circle(image_anot,(r[0],r[1]),r[2],(255,0,0),2)\n",
        "      cv2.putText(image_anot, \"green\", (int(r[0]), int(r[1] - r[2] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
        "      if f == \"00232.jpg\":\n",
        "        print(r)\n",
        "\n",
        "\n",
        "\n",
        "  # print(data_roi_loc)\n",
        "\n",
        "  df_imag_anot = df_test.loc[df_test['filename'] == name_img]\n",
        "  df_imag_anot = df_imag_anot.reset_index()\n",
        "  # print(df_imag_anot)\n",
        "\n",
        "\n",
        "  for i in range(len(df_imag_anot.index)):\n",
        "    xmin_real = df_imag_anot.at[i,\"xmin\"]\n",
        "    xmax_real = df_imag_anot.at[i,\"xmax\"]\n",
        "    ymin_real = df_imag_anot.at[i,\"ymin\"]\n",
        "    ymax_real = df_imag_anot.at[i,\"ymax\"]\n",
        "    bbox_anot = torch.tensor([[xmin_real,ymin_real,xmax_real,ymax_real]], dtype=torch.float)\n",
        "\n",
        "\n",
        "    for j in range(len(data_roi_loc.index)):\n",
        "      xmin_anot = data_roi_loc.at[j,\"xmin\"]\n",
        "      xmax_anot = data_roi_loc.at[j,\"xmax\"]\n",
        "      ymin_anot = data_roi_loc.at[j,\"ymin\"]\n",
        "      ymax_anot = data_roi_loc.at[j,\"ymax\"]\n",
        "\n",
        "      bbox_roi = torch.tensor([[xmin_anot,ymin_anot,xmax_anot,ymax_anot]], dtype=torch.float)\n",
        "\n",
        "      iou1 = ops.box_iou(bbox_roi, bbox_anot)\n",
        "      iou2 = ops.box_iou(bbox_anot,bbox_roi)\n",
        "      if ((iou1 > iou_threshold) or (iou2> iou_threshold)):\n",
        "        data_roi_loc.at[j,\"color\"] = df_imag_anot.at[i,\"color\"]\n",
        "      # print(\"Iou i\", str(i), \" j \", str(j),\" :\",iou.numpy()[0][0], )\n",
        "      if iou > 0:\n",
        "        Iou_count += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # print(data_roi_loc)\n",
        "  data_roi = pd.concat([data_roi, data_roi_loc], ignore_index=True)\n",
        "  # print(data_roi)\n",
        "\n",
        "  if f == \"01082.jpg\":\n",
        "    cv2_imshow(img_original)\n",
        "\n",
        "    cv2_imshow(closed_r)\n",
        "    plt.imshow(closed_r[...,::1])\n",
        "    plt.show()\n",
        "\n",
        "    cv2_imshow(closed_g)\n",
        "    plt.imshow(closed_g[...,::-1])\n",
        "    plt.show()\n",
        "\n",
        "    cv2_imshow(image_anot)\n",
        "    print(data_roi_loc)\n",
        "print(Iou_count)\n",
        "print(data_roi)\n",
        "print(data_roi.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sczdOJqi6JJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usando HOG nas imagens"
      ],
      "metadata": {
        "id": "bZB5_w8FsD01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "for i in range(len(data_roi.index)):\n",
        "  img_name = data_roi.at[i,\"filename\"]\n",
        "  # print(img_name)\n",
        "\n",
        "\n",
        "  #   break\n",
        "  img = cv2.imread('/content/drive/MyDrive/archive/train_dataset/train_images/' + img_name, )\n",
        "  image = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "  x1 = data_roi.at[i,\"xmin\"]\n",
        "  x2 = data_roi.at[i,\"xmax\"]\n",
        "  y1 = data_roi.at[i,\"ymin\"]\n",
        "  y2 = data_roi.at[i,\"ymax\"]\n",
        "\n",
        "  # print(\"Retangulo para cortar\",x1,x2,y1,y2)\n",
        "\n",
        "  cropped_image = image[int(y1):int(y2), int(x1):int(x2)]\n",
        "  cropped_resized = cv2.resize(cropped_image, (hog_w_size,hog_h_size))\n",
        "\n",
        "  gray_image = cv2.cvtColor(cropped_resized, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  features, hog_image = feature.hog(gray_image, orientations=9,\n",
        "                               pixels_per_cell=(cell_size, cell_size), cells_per_block=(cell_block, cell_block),\n",
        "                               visualize=True,\n",
        "                               transform_sqrt=True, block_norm=\"L2-Hys\")\n",
        "  # plt.imshow(hog_image, cmap='gray')\n",
        "  # plt.show()\n",
        "  if (img_name == \"02977.jpg\"):\n",
        "   cv2_imshow(cropped_image)\n",
        "   cv2_imshow(cropped_resized)\n",
        "   plt.imshow(hog_image, cmap='gray')\n",
        "   plt.show()\n",
        "   print(i)\n",
        "  label = data_roi.at[i,\"color\"]\n",
        "  data.append(features)\n",
        "  labels.append(label)\n",
        "  if i< 10:\n",
        "    cv2_imshow(cropped_image)\n",
        "    cv2_imshow(cropped_resized)\n",
        "    plt.imshow(hog_image, cmap='gray')\n",
        "    plt.show()\n",
        "x_test = (np.array(data), np.array(labels))\n",
        "print(len(labels))\n",
        "print(len(data))\n",
        "\n",
        "# print(labels)\n",
        "# print(data)"
      ],
      "metadata": {
        "id": "VPKwQLqssPhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passando pelo classificador"
      ],
      "metadata": {
        "id": "vQEfTGayzmGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_test = np.array(data)\n",
        "y_test = np.array(labels)\n",
        "\n",
        "le = LabelEncoder()\n",
        "# codifique os rótulos de treino\n",
        "y_test = le.fit_transform(y_test)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "t = X_test[0].reshape(1,-1)\n",
        "# print(t)\n",
        "t_pred = model.predict(t)\n",
        "print(t_pred)\n",
        "# accuracy_test = sum(model.predict(X_test)==y_test)/len(y_test)\n",
        "# print(accuracy_test)\n",
        "\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "FJI_e-zozljD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}